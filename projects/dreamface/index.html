<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Bootstrap CSS -->
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">



  <style>
    .thumb {
      text-align: center;
      height: 100px;
      width: auto;
      border: 1px solid #eee;
      box-shadow: 0px 0px 2px #444444;
    }

    pre {
      margin-bottom: 0;
      font-family: Consolas, Monaco, monospace;
      white-space: pre-wrap;
      white-space: -moz-pre-wrap;
      white-space: -pre-wrap;
      white-space: -o-pre-wrap;
      word-wrap: break-word;
      width: 90%;
      color: #444;
      padding: 10px;
      background: #eee;
      border: 1px solid #ccc;
      overflow: auto;
    }
  </style>

  <title>DreamFace: Progressive Generation of Animatable 3D Faces under Text Guidance</title>
</head>

<body>

  <div class="container" style="padding-top: 100px;padding-bottom: 100px;">
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-center">
          <h1>DreamFace: Progressive Generation of Animatable 3D Faces under Text Guidance</h1>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-center">
          Longwen Zhang<sup>1,2</sup>&ensp;&ensp;
          Qiwei Qiu<sup>1,2</sup>&ensp;&ensp;
          Hongyang Lin<sup>1,2</sup>&ensp;&ensp;
          Qixuan Zhang<sup>1,2</sup>&ensp;&ensp;
          Cheng Shi<sup>1</sup>&ensp;&ensp;
          <br>
          Wei Yang<sup>3</sup>&ensp;&ensp;
          Ye Shi<sup>1</sup>&ensp;&ensp;
          Sibei Yang<sup>1</sup>&ensp;&ensp;
          Lan Xu<sup>1</sup>
          Jingyi Yu<sup>1</sup>&ensp;&ensp;
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-center font-weight-light">
          <sup>1</sup>ShanghaiTech University&ensp;&ensp;
          <sup>2</sup>Deemos Technology&ensp;&ensp;
          <sup>3</sup>Huazhong University of Science and Technology
        </div>
      </div>
      <br>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <img src="fig/teaser.jpg" class="img-fluid" alt="Responsive image">
          <i>
            DreamFace generates personalized 3D physically-based facial assets under text guidance, which are compatible
            with the existing CG pipeline, with desired shapes, textures, and fine-grained animations for realistic
            rendering.
          </i>
        </div>
      </div>
    </div>



    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Video</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="embed-responsive embed-responsive-16by9 col-8">
          <iframe class="embed-responsive-item" src="https://www.youtube.com/embed/yCuvzgGMvPM"
            title="YouTube video player" frameborder="0"
            allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture"
            allowfullscreen></iframe>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-center">
          YouTube video
        </div>
      </div>
      <br>
      <div class="row justify-content-center">
        <button class="btn btn-primary" type="button" data-toggle="collapse" data-target="#collapseExample"
          aria-expanded="false" aria-controls="collapseExample">
          show Bilibili source
        </button>
      </div>
      <br>
      <div class="collapse" id="collapseExample">
        <div class="row justify-content-center">
          <div class="embed-responsive embed-responsive-16by9 col-8">
            <iframe class="embed-responsive-item"
              src="//player.bilibili.com/player.html?aid=824348605&bvid=BV1Tg4y1G7ej&cid=1077474149&page=1&autoplay=0"
              scrolling="no" border="0" frameborder="no" framespacing="0" allowfullscreen="true"> </iframe>
          </div>
        </div>
      </div>
    </div>




    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Abstract</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10">
          Emerging Metaverse applications demand accessible, accurate, and easy-to-use tools for 3D digital human
          creations in order to depict different cultures and societies as if in the physical world. Recent large-scale
          vision-language advances pave the way to for novices to conveniently customize 3D content. However, the
          generated CG-friendly assets still cannot represent the desired facial traits for human characteristics. In
          this paper, we present DreamFace, a progressive scheme to generate personalized 3D faces under text guidance.
          It enables layman users to naturally customize 3D facial assets that are compatible with CG pipelines, with
          desired shapes, textures, and fine-grained animation capabilities. From a text input to describe the facial
          traits, we first introduce a coarse-to-fine scheme to generate the neutral facial geometry with a unified
          topology. We employ a selection strategy in the CLIP embedding space to generate coarse geometry, and
          subsequently optimize both the details displacements and normals using Score Distillation Sampling from
          generic Latent Diffusion Model. Then, for neutral appearance generation, we introduce a dual-path mechanism,
          which combines the generic LDM with a novel texture LDM to ensure both the diversity and textural
          specification in the UV space. We also employ a two-stage optimization to perform SDS in both the latent and
          image spaces to significantly provides compact priors for fine-grained synthesis. Our generated neutral assets
          naturally support blendshapes-based facial animations. We further improve the animation ability with
          personalized deformation characteristics by learning the universal expression prior using the cross-identity
          hypernetwork, and a neural facial tracker for video input. Extensive qualitative and quantitative experiments
          validate the effectiveness and generalizability of DreamFace. Notably, DreamFace can generate of realistic 3D
          facial assets with physically-based rendering quality and rich animation ability from video footage, even for
          fashion icons or exotic characters in cartoons and fiction movies.
        </div>
      </div>
    </div>

    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Pipeline</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <img src="fig/overview.jpg" class="img-fluid" alt="Responsive image">
          <br>
          <br>
          The overview of DreamFace. Our pipeline mainly includes three modules, including geometry generation (Sec. 4),
          physically-based texture diffusion (Sec. 5), and animatability empowerment (Sec. 6). Given textual guidance,
          DreamFace is able to generate facial assets that closely resemble the described characteristics in terms of
          shape and appearance. Our approach is consistent with industry standards in computer graphics production and
          is able to achieve
          photo-realistic results when driven and rendered.
        </div>
      </div>
    </div>


    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Gallery</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <img src="fig/Gallery-App.jpg" class="img-fluid" alt="Responsive image">
          <br>
          <br>
          Generated facial assets of celebrities. Our approach generates facial assets of celebrities that capture their
          personalized characteristics and achieve a high degree of resemblance. By generating physically-based
          textures, our facial assets achieve photo-realistic results using the modern CG rendering pipeline.
          <br>
          <br>
          <img src="fig/Gallery-Gen.jpg" class="img-fluid" alt="Responsive image">
          <br>
          <br>
          Generated facial assets from descriptions. Our approach generates facial assets that faithfully match the
          characteristics described in the prompts. Through our animatability empowerment, the generated facial assets
          can be animated using a single RGB image and rendered photo-realistically in modern CG pipelines.
          <br>
          <br>
          <img src="fig/outof.jpg" class="img-fluid" alt="Responsive image">
          <br>
          <br>
          Generation out of distribution. The upper row shows the rendering results from the differentiable renderer,
          and the lower row shows the corresponding diffuse maps. Our framework faithfully reveals the facial
          characteristics of characters, even if they are not present in our texture dataset, for example, the pink nose
          of Na'vi and the metallic patterns of Black Panther's mask. In addition, our texture LDM serves as a robust
          prior, ensuring that the generated facial components share a consistent UV space.
        </div>
      </div>
    </div>


    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Dataset</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <a>Coming soon...</a>
        </div>
      </div>
    </div>

    <!-- 
    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Code</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          We will publish the code and data for training
          [
          <a
            href="https://github.com/ZoneLikeWonderland/Neural-Video-Portrait-Relighting-in-Real-time-via-Consistency-Modeling">DOWNLOAD
            HERE</a>
          ] (coming soon)
        </div>
      </div>
    </div> -->

    <!-- 
    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Downloads</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-auto text-center">
          <a
            href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Neural_Video_Portrait_Relighting_in_Real-Time_via_Consistency_Modeling_ICCV_2021_paper.html">
            <img src="pdf.png" class="img-fluid thumb" style="height: 200px;" alt="Responsive image">
          </a>
          <br>
          Paper (thecvf)
          <br>
          <a
            href="https://openaccess.thecvf.com/content/ICCV2021/html/Zhang_Neural_Video_Portrait_Relighting_in_Real-Time_via_Consistency_Modeling_ICCV_2021_paper.html">link</a>
        </div>
        <div class="col-auto text-center">
          <a href="https://arxiv.org/abs/2104.00484">
            <img src="arxiv.png" class="img-fluid thumb" style="height: 200px;" alt="Responsive image">
          </a>
          <br>
          arXiv
          <br>
          <a href="https://arxiv.org/abs/2104.00484">link</a>
        </div>
      </div>
    </div> -->

    <!-- 
    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Citation</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-9 text-left">
          <pre>
@InProceedings{Zhang_2021_ICCV,
    author    = {Zhang, Longwen and Zhang, Qixuan and Wu, Minye and Yu, Jingyi and Xu, Lan},
    title     = {Neural Video Portrait Relighting in Real-Time via Consistency Modeling},
    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},
    month     = {October},
    year      = {2021},
    pages     = {802-812}
}</pre>
        </div>
      </div>
    </div>
 -->

    <!-- <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Acknowledgments</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          The authors would like to thank all participants of the Light Stage recordings. We also thank the authors of
          Wang et. al. [2020] for providing the results of their method for comparisons.
        </div>
      </div>
    </div> -->
    <!-- 
    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <h2>Contact</h2>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          Longwen Zhang
          <br>
          <a href="mailto:zhanglw2@shanghaitech.edu.cn">zhanglw2@shanghaitech.edu.cn</a>
        </div>
      </div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          Qixuan Zhang
          <br>
          <a href="mailto:zhangqx1@shanghaitech.edu.cn">zhangqx1@shanghaitech.edu.cn</a>
        </div>
      </div>

    </div> -->

    <br>
    <hr>
    <div>
      <div class="row justify-content-center">
        <div class="col-10 text-left">
          <div class="col-4 text-left">
            <script type="text/javascript"
              src="//rf.revolvermaps.com/0/0/7.js?i=5eynijysbx5&amp;m=7&amp;c=ff0000&amp;cr1=ffffff&amp;sx=0"
              async="async"></script>
          </div>
        </div>
      </div>
    </div>

  </div>

  <!-- Optional JavaScript -->
  <!-- jQuery first, then Popper.js, then Bootstrap JS -->
  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
    integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
    crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
    integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
    crossorigin="anonymous"></script>
</body>

</html>